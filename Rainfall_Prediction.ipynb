{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "* چگونه تعادل برای مجموعه داده‌های نامتعادل انجام می‌شود\n",
    "* چگونه رمزگذاری برچسب برای متغیرهای دسته‌ای انجام می‌شود\n",
    "* چگونه روش‌های پیشرفته مانند MICE برای تکمیل داده‌ها استفاده می‌شوند\n",
    "* چگونه می‌توان نقاط ناگوار را شناسایی کرده و از داده‌ها حذف کرد\n",
    "* چگونه روش‌های فیلتر و پوشش برای انتخاب ویژگی‌ها استفاده می‌شوند\n",
    "* چگونه می‌توان مقایسه کرد تعادل سرعت و عملکرد برای مدل‌های محبوب مختلف\n",
    "* کدام معیار می‌تواند بهترین معیار برای ارزیابی عملکرد در مجموعه داده‌های نامتعادل باشد: دقت (Accuracy)، اسکور F1 یا کاپا کوئن (Cohen's Kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "# وارد کردن داده‌ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "full_data = pd.read_csv('weatherAUS.csv')\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "# بررسی داده‌ها\n",
    "ابتدا تعداد ردیف‌ها و ستون‌ها را بررسی خواهیم کرد. سپس اندازه مجموعه داده را برای تصمیم‌گیری در مورد نیاز به فشرده‌سازی اندازه آن بررسی خواهیم کرد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "هر دو \"RainToday\" و \"RainTomorrow\" اشیاء هستند (بله/خیر). ما آن‌ها را به صورت دودویی (1/0) برای راحتی خود تبدیل خواهیم کرد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['RainToday'].replace({'No': 0, 'Yes': 1},inplace = True)\n",
    "full_data['RainTomorrow'].replace({'No': 0, 'Yes': 1},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">بعداً، ما بررسی خواهیم کرد که آیا مجموعه داده ناهمواره است یا متوازن. اگر مجموعه داده ناهموار باشد، ما نیاز داریم که تعداد نمونه‌های اکثریت را کاهش دهیم یا تعداد نمونه‌های اقلیت را افزایش دهیم تا آن را متوازن کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (8,5))\n",
    "full_data.RainTomorrow.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
    "plt.title('RainTomorrow Indicator No(0) and Yes(1) in the Imbalanced Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "می‌توانیم مشاهده کنیم که حضور \"0\" و \"1\" تقریباً به نسبت ۷۸ به ۲ است. بنابراین تراز کلاس وجود دارد و ما باید با آن برخورد کنیم. برای مقابله با تراز کلاس، ما در اینجا از **افزایش تعداد نمونه‌های کلاس اقلیت** استفاده خواهیم کرد. از آنجا که اندازه مجموعه داده به نسبت کوچک است، کاهش تعداد نمونه‌های کلاس اکثریت در اینجا معنی زیادی نخواهد داشت."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "# مدیریت عدم توازن کلاس‌ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "no = full_data[full_data.RainTomorrow == 0]\n",
    "yes = full_data[full_data.RainTomorrow == 1]\n",
    "yes_oversampled = resample(yes, replace=True, n_samples=len(no), random_state=123)\n",
    "oversampled = pd.concat([no, yes_oversampled])\n",
    "\n",
    "fig = plt.figure(figsize = (8,5))\n",
    "oversampled.RainTomorrow.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
    "plt.title('RainTomorrow Indicator No(0) and Yes(1) after Oversampling (Balanced Dataset)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">حالا، ما اکنون الگوی داده‌های از دست رفته را در مجموعه داده بررسی خواهیم کرد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Data Pattern in Training Data\n",
    "import seaborn as sns\n",
    "sns.heatmap(oversampled.isnull(), cbar=False, cmap='PuBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "بطور قابل‌مشاهده، 'تبخیر'، 'تابش نور خورشید'، 'ابرهای ساعت 9 صبح' و 'ابرهای ساعت 3 بعد از ظهر' ویژگی‌هایی هستند که درصد بالایی از داده‌ها در آن‌ها از دست رفته است. بنابراین، ما جزئیات داده‌های از دست رفته برای این 4 ویژگی را بررسی خواهیم کرد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = oversampled.isnull().sum().sort_values(ascending=False)\n",
    "percent = (oversampled.isnull().sum()/oversampled.isnull().count()).sort_values(ascending=False)\n",
    "missing = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">ما مشاهده می‌کنیم که همه چهار ویژگی دارای داده‌های گم‌شده کمتر از ۵۰٪ هستند. بنابراین به جای کاملاً حذف آن‌ها، ما آن‌ها را با روش‌های مناسب در مدل خود در نظر خواهیم گرفت."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "# تکمیل و تبدیل داده\n",
    "در این مرحله، ستون‌های دسته‌ای را با استفاده از مد تکمیل کرده و سپس از رمزگذار برچسبی برای تبدیل آن‌ها به متغیرهای عددی استفاده می‌کنیم. بعد از آن، به کمک بسته MICE (Multiple Imputation by Chained Equations)، مقادیر گم‌شده (مانند NaN و غیره) را تکمیل می‌کنیم. سپس، با استفاده از محدوده بین‌کارها (Inter-Quartile Range)، نقاط نادرست را شناسایی کرده و آن‌ها را حذف کرده و به مجموعه داده نهایی می‌رسیم. در نهایت، ارتباط بین متغیرهای مختلف را بررسی کرده و اگر هر گونه جفت متغیر با ارتباط بالایی پیدا کنیم، یکی از آن‌ها را حذف کرده و دیگری را حفظ می‌کنیم.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute categorical var with Mode\n",
    "oversampled['Date'] = oversampled['Date'].fillna(oversampled['Date'].mode()[0])\n",
    "oversampled['Location'] = oversampled['Location'].fillna(oversampled['Location'].mode()[0])\n",
    "oversampled['WindGustDir'] = oversampled['WindGustDir'].fillna(oversampled['WindGustDir'].mode()[0])\n",
    "oversampled['WindDir9am'] = oversampled['WindDir9am'].fillna(oversampled['WindDir9am'].mode()[0])\n",
    "oversampled['WindDir3pm'] = oversampled['WindDir3pm'].fillna(oversampled['WindDir3pm'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features to continuous features with Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lencoders = {}\n",
    "for col in oversampled.select_dtypes(include=['object']).columns:\n",
    "    lencoders[col] = LabelEncoder()\n",
    "    oversampled[col] = lencoders[col].fit_transform(oversampled[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Imputation by Chained Equations\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "MiceImputed = oversampled.copy(deep=True) \n",
    "mice_imputer = IterativeImputer()\n",
    "MiceImputed.iloc[:, :] = mice_imputer.fit_transform(oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MiceImputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">حالا، ما بررسی می‌کنیم که آیا تمام مقادیر \"NaN\" به طور کامل ترمیم شده‌اند یا خیر."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MiceImputed.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">پس از تخمین با MICE، دیتافریم دیگر هیچ مقدار \"NaN\" ندارد. اکنون ما قصد داریم نویزها را از مجموعه داده بر اساس دامنه میانکاره رد کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting outliers with IQR\n",
    "Q1 = MiceImputed.quantile(0.25)\n",
    "Q3 = MiceImputed.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers from dataset\n",
    "MiceImputed = MiceImputed[~((MiceImputed < (Q1 - 1.5 * IQR)) |(MiceImputed > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "MiceImputed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "corr = MiceImputed.corr()\n",
    "mask = np.triu(np.ones_like(corr))\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "cmap = sns.diverging_palette(250, 25, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=None, center=0,square=True, annot=True, linewidths=.5, cbar_kws={\"shrink\": .9})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "در زیر، جفت‌های ویژگی‌هایی که بین آن‌ها همبستگی بالایی وجود دارد آمده است:\n",
    "\n",
    "* حداکثر دما و حداقل دما\n",
    "* فشار ساعت 9 صبح و فشار ساعت 3 بعد از ظهر\n",
    "* دما ساعت 9 صبح و دما ساعت 3 بعد از ظهر\n",
    "* تبخیر و حداکثر دما\n",
    "* حداکثر دما و دما ساعت 3 بعد از ظهر\n",
    "\n",
    "اما در هیچ یک از موارد، مقدار همبستگی به صورت کاملاً \"1\" نیست. بنابراین هیچ ویژگی را حذف نمی‌کنیم.\n",
    "\n",
    "با این حال، می‌توانیم به عمق در همبستگی جفتی بین این ویژگی‌های با همبستگی بالا نگاه کنیم، با توجه به نمودار جفتی زیر. هر یک از نمودارهای جفتی به وضوح خوشه‌های قابل تمییزی از \"بله\" و \"خیر\" برای باران فردا نشان می‌دهد. همگی دارای اشتراک بسیار کمی هستند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot( data=MiceImputed, vars=('MaxTemp','MinTemp','Pressure9am','Pressure3pm', 'Temp9am', 'Temp3pm', 'Evaporation'), hue='RainTomorrow' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "# انتخاب ویژگی\n",
    "برای انتخاب ویژگی، از روش فیلتر و روش پوشش‌دهنده استفاده خواهیم کرد.\n",
    "\n",
    "**(1) انتخاب ویژگی با استفاده از روش فیلتر (مقدار کای-مربع):** قبل از انجام این کار، نیاز داریم که داده‌های خود را استاندارد کنیم. ما از MinMaxScaler به جای StandardScaler استفاده می‌کنیم تا از ایجاد مقادیر منفی جلوگیری کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing data\n",
    "from sklearn import preprocessing\n",
    "r_scaler = preprocessing.MinMaxScaler()\n",
    "r_scaler.fit(MiceImputed)\n",
    "modified_data = pd.DataFrame(r_scaler.transform(MiceImputed), index=MiceImputed.index, columns=MiceImputed.columns)\n",
    "modified_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance using Filter Method (Chi-Square)\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X = modified_data.loc[:,modified_data.columns!='RainTomorrow']\n",
    "y = modified_data[['RainTomorrow']]\n",
    "selector = SelectKBest(chi2, k=10)\n",
    "selector.fit(X, y)\n",
    "X_new = selector.transform(X)\n",
    "print(X.columns[selector.get_support(indices=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "می‌توانیم مشاهده کنیم که \"Sunshine\"، \"Humidity9am\"، \"Humidity3pm\"، \"Pressure9am\" و \"Pressure3pm\" اهمیت بالاتری نسبت به ویژگی‌های دیگر دارند.\n",
    "\n",
    "**(2) انتخاب ویژگی با استفاده از روش Wrapper (جنگل تصادفی):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "\n",
    "X = MiceImputed.drop('RainTomorrow', axis=1)\n",
    "y = MiceImputed['RainTomorrow']\n",
    "selector = SelectFromModel(rf(n_estimators=100, random_state=0))\n",
    "selector.fit(X, y)\n",
    "support = selector.get_support()\n",
    "features = X.loc[:,support].columns.tolist()\n",
    "print(features)\n",
    "print(rf(n_estimators=100, random_state=0).fit(X,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "این خیلی جالب است که تمام اهمیت‌های ویژگی به جز RISK_MM به نزدیک صفر می‌رسند. این در دو حالت ممکن است رخ دهد. یا زمانی که تمام ویژگی‌ها دارای همبستگی بالا با یکدیگر باشند، یا زمانی که ویژگی‌ها در واقع اهمیت نسبی بسیار پایینی نسبت به متغیر هدف داشته باشند. از آنجا که ما در حالت قبلی همبستگی را رسم کرده‌ایم، می‌دانیم که احتمال اول درست نیست. ما با استفاده از اهمیت جابجایی (Permutation Importance) بررسی می‌کنیم که آیا احتمال دوم درست است یا خیر."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(rf(n_estimators=100, random_state=0).fit(X,y),random_state=1).fit(X,y)\n",
    "eli5.show_weights(perm, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "# آموزش با مدل‌های مختلف\n",
    "ما کل مجموعه داده را به دو بخش آموزش (75%) و آزمایش (25%) تقسیم می‌کنیم. برای به دست آوردن نتایج بهتر، داده‌های X_train و X_test خود را استاندارد می‌کنیم (یعنی ویژگی‌ها بدون هدف برای مجموعه‌های داده آموزش و آزمایش)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = MiceImputed[['Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustDir', \n",
    "                       'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', \n",
    "                       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm', \n",
    "                       'RainToday']]\n",
    "target = MiceImputed['RainTomorrow']\n",
    "\n",
    "# Split into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Normalize Features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_cur(fper, tper):  \n",
    "    plt.plot(fper, tper, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, cohen_kappa_score, ConfusionMatrixDisplay, roc_curve, classification_report\n",
    "def run_model(model, X_train, y_train, X_test, y_test, verbose=True):\n",
    "    t0=time.time()\n",
    "    if verbose == False:\n",
    "        model.fit(X_train,y_train, verbose=0)\n",
    "    else:\n",
    "        model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred) \n",
    "    coh_kap = cohen_kappa_score(y_test, y_pred)\n",
    "    time_taken = time.time()-t0\n",
    "    print(\"Accuracy = {}\".format(accuracy))\n",
    "    print(\"ROC Area under Curve = {}\".format(roc_auc))\n",
    "    print(\"Cohen's Kappa = {}\".format(coh_kap))\n",
    "    print(\"Time taken = {}\".format(time_taken))\n",
    "    print(classification_report(y_test,y_pred,digits=5))\n",
    "    \n",
    "    probs = model.predict_proba(X_test)  \n",
    "    probs = probs[:, 1]  \n",
    "    fper, tper, thresholds = roc_curve(y_test, probs) \n",
    "    plot_roc_cur(fper, tper)\n",
    "    \n",
    "    ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
    "    \n",
    "    return model, accuracy, roc_auc, coh_kap, time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "**مدل ۱: رگرسیون لجستیک تنظیم شده توسط لسو**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "params_lr = {'penalty': 'l1', 'solver':'liblinear'}\n",
    "\n",
    "model_lr = LogisticRegression(**params_lr)\n",
    "model_lr, accuracy_lr, roc_auc_lr, coh_kap_lr, tt_lr = run_model(model_lr, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "**مدل-2: درخت تصمیم**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params_dt = {'max_depth': 16,\n",
    "             'max_features': \"sqrt\"}\n",
    "\n",
    "model_dt = DecisionTreeClassifier(**params_dt)\n",
    "model_dt, accuracy_dt, roc_auc_dt, coh_kap_dt, tt_dt = run_model(model_dt, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "**مدل-3: شبکه عصبی (مولتی لایه پرسپترون)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "params_nn = {'hidden_layer_sizes': (30,30,30),\n",
    "             'activation': 'logistic',\n",
    "             'solver': 'lbfgs',\n",
    "             'max_iter': 500}\n",
    "\n",
    "model_nn = MLPClassifier(**params_nn)\n",
    "model_nn, accuracy_nn, roc_auc_nn, coh_kap_nn, tt_nn = run_model(model_nn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "**مدل-۴: جنگل تصادفی**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params_rf = {'max_depth': 16,\n",
    "             'min_samples_leaf': 1,\n",
    "             'min_samples_split': 2,\n",
    "             'n_estimators': 100,\n",
    "             'random_state': 12345}\n",
    "\n",
    "model_rf = RandomForestClassifier(**params_rf)\n",
    "model_rf, accuracy_rf, roc_auc_rf, coh_kap_rf, tt_rf = run_model(model_rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "**مدل-۵: Light GBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "params_lgb ={'colsample_bytree': 0.95, \n",
    "         'max_depth': 16, \n",
    "         'min_split_gain': 0.1, \n",
    "         'n_estimators': 200, \n",
    "         'num_leaves': 50, \n",
    "         'reg_alpha': 1.2, \n",
    "         'reg_lambda': 1.2, \n",
    "         'subsample': 0.95, \n",
    "         'subsample_freq': 20}\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(**params_lgb)\n",
    "model_lgb, accuracy_lgb, roc_auc_lgb, coh_kap_lgb, tt_lgb = run_model(model_lgb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "**مدل-6: CatBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "params_cb ={'iterations': 50,\n",
    "            'max_depth': 16}\n",
    "\n",
    "model_cb = cb.CatBoostClassifier(**params_cb)\n",
    "model_cb, accuracy_cb, roc_auc_cb, coh_kap_cb, tt_cb = run_model(model_cb, X_train, y_train, X_test, y_test, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "**مدل-7: XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "params_xgb ={'n_estimators': 500,\n",
    "            'max_depth': 16}\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(**params_xgb)\n",
    "model_xgb, accuracy_xgb, roc_auc_xgb, coh_kap_xgb, tt_xgb = run_model(model_xgb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "# ترسیم منطق تصمیم برای تمام مدل‌ها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "value = 1.80\n",
    "width = 0.90\n",
    "\n",
    "clf1 = LogisticRegression(random_state=12345)\n",
    "clf2 = DecisionTreeClassifier(random_state=12345) \n",
    "clf3 = MLPClassifier(random_state=12345, verbose = 0)\n",
    "clf4 = RandomForestClassifier(random_state=12345)\n",
    "clf5 = lgb.LGBMClassifier(random_state=12345, verbose = 0)\n",
    "clf6 = cb.CatBoostClassifier(random_state=12345, verbose = 0)\n",
    "clf7 = xgb.XGBClassifier(random_state=12345)\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf4, clf5, clf6, clf7], weights=[1, 1, 1, 1], voting='soft')\n",
    "\n",
    "X_list = MiceImputed[[\"Sunshine\", \"Humidity9am\", \"Cloud3pm\"]] #took only really important features\n",
    "X = np.asarray(X_list, dtype=np.float32)\n",
    "y_list = MiceImputed[\"RainTomorrow\"]\n",
    "y = np.asarray(y_list, dtype=np.int32)\n",
    "\n",
    "# Plotting Decision Regions\n",
    "gs = gridspec.GridSpec(3,3)\n",
    "fig = plt.figure(figsize=(18, 14))\n",
    "\n",
    "labels = ['Logistic Regression',\n",
    "          'Decision Tree',\n",
    "          'Neural Network',\n",
    "          'Random Forest',\n",
    "          'LightGBM',\n",
    "          'CatBoost',\n",
    "          'XGBoost',\n",
    "          'Ensemble']\n",
    "\n",
    "for clf, lab, grd in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7, eclf],\n",
    "                         labels,\n",
    "                         itertools.product([0, 1, 2],\n",
    "                         repeat=2)):\n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, \n",
    "                                filler_feature_values={2: value}, \n",
    "                                filler_feature_ranges={2: width}, \n",
    "                                legend=2)\n",
    "    plt.title(lab)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "\n",
    "می‌توانیم تفاوت در مرزهای کلاس برای مدل‌های مختلف را مشاهده کنیم، از جمله مدل *انسمبل* (نمودار‌ها با در نظر گرفتن داده‌های آموزش انجام شده است). CatBoost مرز منطقه‌ای متمایزی نسبت به تمام مدل‌های دیگر دارد. با این حال، مدل‌های XGBoost و Random Forest نیز تعداد بسیار کمتری از نقاط داده‌های اشتباه طبقه‌بندی‌شده را نسبت به مدل‌های دیگر دارند.\n",
    "\n",
    "# مقایسه مدل\n",
    "\n",
    "حالا باید تصمیم بگیریم که کدام مدل بر اساس امتیاز دقت، ROC_AUC، کوهن's کاپا و زمان کلی اجرا بهترین عملکرد را داشته است. نکته‌ای که در اینجا قابل توجه است: می‌توانستیم F1-Score را به عنوان معیار بهتری برای ارزیابی عملکرد مدل در نظر بگیریم تا دقت، اما ما قبلاً مجموعه داده‌های نامتعادل را به یک مجموعه داده متعادل تبدیل کرده‌ایم، بنابراین در نظر گرفتن دقت به عنوان یک معیار برای تصمیم‌گیری در مورد بهترین مدل در این مورد توجیه می‌شود. برای تصمیم‌گیری بهتر، ما **\"کوهن's کاپا\"** را انتخاب کرده‌ایم که در واقع یک انتخاب ایده‌آل به عنوان معیار برای تصمیم‌گیری در مورد مجموعه‌های داده نامتعادل است. بیایید بررسی کنیم که کدام مدل در کدام جنبه‌ها بهتر عمل کرده است."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = [accuracy_lr, accuracy_dt, accuracy_nn, accuracy_rf, accuracy_lgb, accuracy_cb, accuracy_xgb]\n",
    "roc_auc_scores = [roc_auc_lr, roc_auc_dt, roc_auc_nn, roc_auc_rf, roc_auc_lgb, roc_auc_cb, roc_auc_xgb]\n",
    "coh_kap_scores = [coh_kap_lr, coh_kap_dt, coh_kap_nn, coh_kap_rf, coh_kap_lgb, coh_kap_cb, coh_kap_xgb]\n",
    "tt = [tt_lr, tt_dt, tt_nn, tt_rf, tt_lgb, tt_cb, tt_xgb]\n",
    "\n",
    "model_data = {'Model': ['Logistic Regression','Decision Tree','Neural Network','Random Forest','LightGBM','Catboost','XGBoost'],\n",
    "              'Accuracy': accuracy_scores,\n",
    "              'ROC_AUC': roc_auc_scores,\n",
    "              'Cohen_Kappa': coh_kap_scores,\n",
    "              'Time taken': tt}\n",
    "data = pd.DataFrame(model_data)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12,10))\n",
    "ax1.set_title('Model Comparison: Accuracy and Time taken for execution', fontsize=13)\n",
    "color = 'tab:green'\n",
    "ax1.set_xlabel('Model', fontsize=13)\n",
    "ax1.set_ylabel('Time taken', fontsize=13, color=color)\n",
    "ax2 = sns.barplot(x='Model', y='Time taken', data = data, palette='summer')\n",
    "ax1.tick_params(axis='y')\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Accuracy', fontsize=13, color=color)\n",
    "ax2 = sns.lineplot(x='Model', y='Accuracy', data = data, sort=False, color=color)\n",
    "ax2.tick_params(axis='y', color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax3 = plt.subplots(figsize=(12,10))\n",
    "ax3.set_title('Model Comparison: Area under ROC and Cohens Kappa', fontsize=13)\n",
    "color = 'tab:blue'\n",
    "ax3.set_xlabel('Model', fontsize=13)\n",
    "ax3.set_ylabel('ROC_AUC', fontsize=13, color=color)\n",
    "ax4 = sns.barplot(x='Model', y='ROC_AUC', data = data, palette='winter')\n",
    "ax3.tick_params(axis='y')\n",
    "ax4 = ax3.twinx()\n",
    "color = 'tab:red'\n",
    "ax4.set_ylabel('Cohen_Kappa', fontsize=13, color=color)\n",
    "ax4 = sns.lineplot(x='Model', y='Cohen_Kappa', data = data, sort=False, color=color)\n",
    "ax4.tick_params(axis='y', color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "\n",
    "# نتیجه‌گیری\n",
    "می‌توانیم مشاهده کنیم که **XGBoost، CatBoost و Random Forest** به مقایسه با مدل‌های دیگر بهتر عمل کرده‌اند. با این حال، اگر سرعت یک ملاحظه مهم باشد، می‌توانیم به جای XGBoost یا CatBoost به Random Forest پایبند باشیم."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
